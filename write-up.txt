lab5 write-up
By Tongxi(Tom) Liu, Jessie Zeng
Feb 2nd, 2022
1.
Phenomenon 1: Possessive

In lab4, we correctly defined the suffix possessive marker (=ki), and created noun-pc for possessive pronominal prefixes (í-(my)/nə́-(your)/mə́-(his or her)). However, when defined the following persudo-features cause errors in our grammar:
{    
      feature1_name=poss-pron1
      feature1_type=head
      feature1_cat=noun
      feature1_new=yes
	feature1_value1_name=possessive
	  feature1_value1_supertype1_name=poss-pron1
	feature1_value2_name=nonpossessive
	  feature1_value2_supertype1_name=poss-pron1
}

In the lecture this week, you kindly helped us figure out the semantics unmatching in defining persudo-features. Instead, we should define a poss-pron1 under adnom-poss section:
{
	section=adnom-poss
	  poss-strat1_order=head-final
	  poss-strat1_mod-spec=mod
	  poss-strat1_mark-loc=possessor
	  poss-strat1_possessor-type=affix
	  poss-strat1_possessor-affix-agr=non-agree
	  poss-strat1_possessum-type=affix
	  poss-strat1_possessum-affix-agr=non-agree
	  poss-pron1_type=affix
	  poss-pron1_agr=non-agree
	  poss-pron1_mod-spec=spec
}

Then, we assigned this feature with person feature to our noun-pc46:
{
  noun-pc46_name=noun-possessum-pc
  noun-pc46_order=prefix
  noun-pc46_inputs=noun1, noun2, noun61, noun79
    noun-pc46_lrt1_name=noun-possessum-pc_lrt1
      noun-pc46_lrt1_feat1_name=poss-pron1
      noun-pc46_lrt1_feat1_value=plus
      noun-pc46_lrt1_feat1_head=itself
      noun-pc46_lrt1_feat2_name=person
      noun-pc46_lrt1_feat2_value=1st
      noun-pc46_lrt1_feat2_head=possessor
      noun-pc46_lrt1_lri1_inflecting=yes
      noun-pc46_lrt1_lri1_orth=í-
    noun-pc46_lrt2_name=noun-possessum-pc_lrt2
      noun-pc46_lrt2_feat1_name=poss-pron1
      noun-pc46_lrt2_feat1_value=plus
      noun-pc46_lrt2_feat1_head=itself
      noun-pc46_lrt2_feat2_name=person
      noun-pc46_lrt2_feat2_value=2nd
      noun-pc46_lrt2_feat2_head=possessor
      noun-pc46_lrt2_lri1_inflecting=yes
      noun-pc46_lrt2_lri1_orth=nə́-
    noun-pc46_lrt3_name=noun-possessum-pc_lrt3
      noun-pc46_lrt3_feat1_name=poss-pron1
      noun-pc46_lrt3_feat1_value=plus
      noun-pc46_lrt3_feat1_head=itself
      noun-pc46_lrt3_feat2_name=person
      noun-pc46_lrt3_feat2_value=3rd
      noun-pc46_lrt3_feat2_head=possessor
      noun-pc46_lrt3_lri1_inflecting=yes
      noun-pc46_lrt3_lri1_orth=mə́-
}

Here are some IGTs to test:
	í-mí kə́p-e
	1P-man cry-ASRT
	'My man cries.'
	
	nə́-mí kə́p-e
	2P-man cry-ASRT
	'Your man cries.'

	mə́-mí kə́p-e
	3P-man cry-ASRT
	'His/her man cries.'

Each IGT should have two parses results with identical MRS. The source of the two results comes from applying different head rules. In MRS of each NP contains the possessive pronominal prefix, the pron_rel now has correct PNG.PER value corresponding to each prefix while _man_n_rel always has PER 3rd value. The source of the two results comes from applying different head rules.

Phenomenon 2: Coordination & Case
When testing the following IGT for cases:
	húy garí=pu tan-e
	dog car=ACC chase-ASRT
	'Dog(s) chase car(s).'

The semantic was incorrect since it takes "dog" and "car=ACC" as a constituent, and translation in ACE shows "dogs and cars chase." This was an incorrect result and we guess it was related to coordination. We didn't start to improve coordination yet. However, we found our default choice file has the following defination for coordination:
{
	cs1_vp=on
	cs1_pat=a
	cs2_np=on
	cs2_pat=a
}

And we started to test some random pairs of nouns that appear in a sequence, such as:
	yúmtə mí ləyí
	yúm=tə mí ləy-í
	house=LOC man be-NHYP
	'(A) man live in house.'

It has incorrect MRS interpreted as "In house and man be/live." Therefore, we decided to remove the coordination defination from our choice file for now. However, we found the following IGT cannot parse since "car=ACC" and "chase-ASRT" cannot form a constituent.
	húy garí=pu tan-e
	dog car=ACC chase-ASRT
	'Dog(s) chase car(s).'

We investigated the lexicon defination for _chase_v_rel and found it has valence of "intrans." We fixed it by changing it to "nom-acc." Now, above IGT can be parse correct with only one reading.
{
  verb12_valence=nom-acc
    verb12_stem1_orth=tan
    verb12_stem1_pred=_chase_v_rel
}

Phenomenon 3: TODO

2.
A description of your process for translating the MMT sentences and your documentation about which sentences may be impossible.

We tried to translate the following three sentences:
	# 1
	húy túm-e
	dog sleep-ASRT
	'Dog(s) sleep.'
	# 2
	húy garí=pu tan-e
	dog car=ACC chase-ASRT
	'Dog(s) chase car(s).'
	# 3
	ə́y nə́ŋ=pu tan-e
	I you=ACC chase-ASRT
	'I chase you.'

First, we didn't make any modifications to our grammar and attempted to translate them into English. We found it cannot find some PRED values, such as _dog_n_rel, _car_n_rel, _chase_n_rel, so we went to our text to find the corresponding lexicons and added them into our choice file:
{
    noun1_stem265_orth=húy
    noun1_stem265_pred=_dog_n_rel
    noun1_stem266_orth=garí
    noun1_stem266_pred=_car_n_rel
    verb12_stem2_orth=tan
    verb12_stem2_pred=_chase_v_rel
}

Now, we found sentence # 1 can be translated, but with a list of results:
{
	Dogs will sleep
	The dogs sleep
	A dog slept
	A dog sleeps
	The dog slept
	Dogs slept
	A dog will sleep
	The dogs will sleep
	The dog will sleep
	Dogs sleep
	The dogs slept
	The dog sleeps
}

These results are reasonable since Meitei does not mark nouns with numbers, determiners are optional, nor has tense markers. These are all possible interpretations for sentence # 1.

However, when translating sentences # 2 and #3, we were getting incorrect results:
{
	# 2
	Dogs and cars chase
	A dog and a car chase
	Dogs and a car chase
	...
	# 3
	You and I chased
	Him and you chased
	Him and us will chase
	He and we chase
	Her and she chased
	...
}

We then investigated MRS in our parsed tree for sentences #2 and # 3 and realized it was a problem of incorrect coordination rule as stated in the Problem 1 Phenomenon Coordination section. After fixing, we got reasonable results:
{
	# 2
	Dogs chased cars
	Dogs chased a car
	The dogs chased the car
	The dog chased cars
	A dog chased the car
	...
	# 3
	I chased it
	You chased me
	It chases it
	We chased her
	He chased us
	It chased him
	You chased it
	You chase us
	...
}


3.
A description what happened when you tried the MT set up. What difficulties did you encounter and how did you resolve them? What output did you get?

I followed the instructions in lab5, and everything worked perfectly. The primary difficulty was modifying the choice file (especially adding/changing PRED values as stated above). The slight problem is that we noticed sentence # 3 is still weird since we confirm it is parsed correctly in semantics (with the correct number and person). However, the results have all possible combinations of number and person. You answered in the discussion, "This is probably an issue with the variable property mapping --- something we will work on next week." So we left it for now.

When translating English into Meitei, it processed very slow and generated 25229 results for the sentence "Dogs sleep." This was probably because Meitei has a lot of mood/aspect and other noun/verbal affixes that can build up together. Thus, more complicated sentences, such as "a dog chase a car" and "I chase you," are unable to translate to Meitei with our current grammar. We hope to improve this in our MT system in the future.

4.1.
  Before improvements:
  	test corpus: 86/1784 items parsed;
  	test suite: 2/17 items parsed (with 1 ungrammatical sentence parse).
  After improvements:
  	test corpus: 71/1784 items parsed (p.s. probably because we removed incorrect coordination rule that combined nouns/verbs freely so that our improvements eliminated some false-positive results);
  	test suite: all (12/17) items parsed (with 5 ungrammatical sentences eliminated).

4.2.
  Before improvements:
  	test corpus: 95.45 parses on average;
  	test suite: 140 parses on average.
  After improvements:
  	test corpus: 5.28 parses on average;
  	test suite: 2.33 parses on average.

4.3.
  Before improvements:
  	test corpus: 840 parses;
  	test suite: 256 parses.
  After improvements:
  	test corpus: 104 parses;
  	test suite: 7 parses;

4.4.
  Before improvements:
    TODO
  After improvements:
    TODO

4.5.
  Before improvements:
    TODO
  After improvements:
    TODO

